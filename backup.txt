<h2>Introduction</h2>

Have you ever wondered how multiplayer games read and write packets?

If you come from a web development background you've probably used XML, JSON, YAML to send data over the network in text format. But multiplayer games don't usually send packets encoded this way. In fact game programmers would laugh at you if suggested doing such a thing. You're fired! Why is this?

The key difference between web development and multiplayer games is that while web is stateless (REST), multiplayer games are the opposite: extremely stateful. 

(diagrams potentially showing the difference between request/response and the continual stream of network data in action games)

A web server sits there and listens for requests and replies with responses and is designed this way so it can scale to support a large number of requests per-second. Multiplayer games are essentially a simulation of the game world running on a server that envolves over time according to inputs sent from each client (keyboard, mouse, controller). The primitive here is not request/response but a continual stream of inputs sent from client -> server and a continual stream of world state from server -> clients at some fixed rate over UDP.

The world state is very large and synchronizing it to clients accounts for the majority of the bandwidth used by multiplayer games. The world often consists of thousands of entities with hundreds or thousands of properties per-object. If you attempted to encode this world state using a text format like XML or JSON it is extremely inefficient in terms of bandwidth because so much attribution data is wrapped around the actual data to describe what is being sent.

<pre>
... example of a world state encoded in xml/json ...
</pre>

Can you do better with text? Sure. You could design your own text format for data, something something.

<pre>
... example of your own custom format ...
</pre>

So you can remove some of the atribution with a custom text format, but you'll notice that for integer values that only need one byte to send, eg. 255, you need three characters and a separator, eg ',' This is 4 bytes. It's much worse for floating point values. So at this point we can agree that sending data over text is inefficient and should generally be avoided where bandwidth is important.

Of course everybody in the web world knows that libraries exist to read and write binary formats over the wire like Protocol Buffers, Flatbuffers, Thrift and Cap'n Proto. These libraries take your native language data structures and with the help of an interface language and some code generation create the glue code to read and write ("serialize") your data structures into a binary format over the network. You don't have to get your hands dirty hand-writing serialization code and these protocols provide versioning so a client running an older version of your protocol can talk to a server running a newer version.

So these libraries seem promising. Are they a good way to implement your network protocol. In some cases yes.

But the performance critical networking we're talking about in this article (FPS, action games and so on) simply don't need versioning! These games cut the gordian knot of versioning and simply disallow clients from connecting to servers with different versions. So if we don't need versioning what are the benefits left for these libraries? Not much in my opinion. We can just cut to the chase and write our own unattributed binary stream instead, gaining much more control and flexibility over the data format.

<h2>Getting started with a simple binary format</h2>

If you are coding your game in C or C++ you may wonder, why can't I just memcpy my structs into the packet and send that?

You could do something simple like setup a packet union type like this:

<pre>
struct Packet
{
    enum PacketTypeEnum { PACKET_A, PACKET_B, PACKET_C };

    int packetType;
    
    union
    {
        struct PacketA
        {
            ...
        } a;

        struct PacketB
        {
            ...
        } b;

        struct PacketC
        {
            ...
        } c;
    };  
};
</pre>

Then when you write your packet you could just set the first integer in the packet to the packet type, and depending on the packet type a,b or c, memcpy in the appropriate union struct into the rest of the packet. On read you do the reverse. Read in the first integer, then according to the packet type you know how much data is left and you memcpy that data from the packet into the union struct. You should of course check that the packet size matches the expected size of the struct you are copying to.

<pre>
... example code showing packet read/write ...
</pre>

But there is are quite few weaknesses with this approach!

The first and perhaps most cricical is that different compilers and platforms support different packing of data structs. You'll spend a lot of time with #pragma pack trying to make sure that different compilers on different platforms lay out the structures in memory exactly the same way. Getting this to work across 32bit and 64bit architectures could be a lot of fun. Not that it's impossible to make this work but it's not trivial.

The next big one is endianness. Modern computers are mostly little endian these days (Intel) but PowerPC and other cores are big endian and historically network data is sent over the wire in big endian format (network byte order). Of course since you are writing your own custom binary protocol you can decide to send data over the wire in whatever format you want, as long as the format on the sender side matches the receiver everything works out. But if you need to support communication between little endian and big endian machines, this memcpy the struct into the packet approach won't work, or at minimum you'll need to write a function to pass over the struct after it is read in to apply endian fix-up. This is a pain in the ass.

There are some other minor issues. Obviously if your struct contains pointers you can't just serialize that structure over the network and expect that pointer to be valid on the other side. Also, if you have variable sized structures, eg. an array up to 32 elements, but it is empty or only has a few elements in it, you need to serialize the entire structure at fixed maximum size always, eg. 32 elements which is wasteful. A more advanced approach would let you only take the hit for the data that is actually used and would allow a variable length encoding of your structures.

The final issue that I think really drives a stake into the heart of this approach is security. You are directly memcpying in a block of data sent over the network into a C++ struct. What if your structure contains int elementCount for an array and a malicious attacker sets that to 0xFFFFFFFF causing you to trash all over memory when you process that packet? It's a massive security risk to just take data coming in over the network and trust it. You should at least try some sort of checking, and per-field check that it is in range and matches what you are expecting vs. blindly accepting what is sent to you.

<h2>Read and write functions per-struct</h2>
 
The next step is to implement read and write functions per-packet. You can add a simple set of operations like this:

<pre>
void WriteInteger( Packet & packet, uint32_t value );
void WriteShort( Packet & packet, uint16_t value );
void WriteChar( Packet & packet, uint8_t value );

uint32_t ReadInteger( Packet & packet );
uint16_t ReadShort( Packet & packet );
uint8_t ReadByte( Packet & packet );
</pre>

These operations work on a packet structure, which is just a wrapper around a small array with an index to the next byte to be read or written.

<pre>
struct Packet
{
    uint8_t *data;    // pointer to packet data
    int size;         // size of packet data (bytes)
    int index;        // index of next byte to be read/written
};
</pre>

For example the write integer function would look like this:

<pre>
void WriteInteger( Packet & packet, uint32_t value )
{
    assert( packet.index + 4 <= size );
#ifdef LITTLE_ENDIAN
    *((uint32_t*)(packet.data+packet.index)) = value;
#else // #ifdef LITTLE_ENDIAN
    *((uint32_t*)(packet.data+packet.index)) = bswap( value );
#endif // #ifdef LITTLE_ENDIAN
    packet.index += 4;
}
</pre>

And the corresponding read function looks like this:

<pre>
uint32_t ReadInteger( Packet & packet )
{
    assert( packet.index + 4 <= size );
    uint32_t value;
#ifdef LITTLE_ENDIAN
    value = *((uint32_t*)(packet.data+packet.index));
#else // #ifdef LITTLE_ENDIAN
    value = bswap( *((uint32_t*)(packet.data+packet.index)) );
#endif // #ifdef LITTLE_ENDIAN
    packet.index += 4;
    return value;
}
</pre>

As you can see above integers are sent over the network in little endian format, which is contrary to normal network tradition but seeing as most machines these days are little endian why waste any CPU converting to/from big endian integer format over the wire? It's your protocol, you can do whatever you want.

Now that we have these read/write functions that handle endian differences, we add read and write functions for each packet type:

<pre>
... todo example code showing read/write functions for each packet type ...
</pre>

And when reading and writing packets, we prefix the packet data with the packet type, perhaps written as a byte WriteByte/ReadByte, then according to the packet type, we call the read/write on the corresponding packet struct in the union:

<pre>
... todo, example code showing full read/write at the packet level w. union ...
</pre>

So here we haev a simple system that allows clients on different endian machines to communication, supports a variable length encoding, for example serializing array length and iterating only for that number of elements, vs. copying in the entire array at worst case size, as well as supporting some basic validation.

There are still some problems though and we can do much better.

First problem: if we have a value in the range [0,1000] it really only needs 10 bits to represent all possible values, but since we can only serialize a byte [0,255], a short [0,65535] or a full 32 bit integer, we have to round up to 16 bits and waste bandwidth by sending data with more bits than is necessary. Similarly, bool values (true/false) really only need one bit, but have to be rounded up to a byte.

Now you can try getting around this by implementing packing in your C++ structures and serializing C++ bitfields, but you run into the same problem as this. Do you really have a guarantee that two completely different C++ compilers pack bitfields exactly the same? Can you rely on this? Probably for a few cases but not all. To my understanding the exact bitpacking details for C++ bitfields leaves enough flexibility to the compiler that they are not required to pack bits exactly the same way, and if you are reading and writing a 32bit integer with C++ bitfields in it, written by one compiler (perhaps GCC or clang on the server-side) and read by another compiler like Visual C++ on the client-side do you really want to have your game break because of compiler differences?

So what we really want is a way to serialize at a bit-level rather than a byte level. We want a bool to take 1 bit over the network and a 5 bit value to only require 5 bits, not 8.

To do this we need to implement our own bitpacker.

<h2>Implementing a bitpacker</h2>

Now we need to separate read and write because they are going to behave differently. 

First up we have the class for writing packed bits:

<pre>
class BitWriter
{
public:

    BitWriter( void* data, int bytes );

    void WriteBits( uint32_t value, int bits );

    void FlushBits();

    int GetAlignBits() const;

    int GetBitsWritten() const;

    int GetBitsAvailable() const;

    const uint8_t* GetData() const;

    int GetBytesWritten() const;

    int GetTotalBytes() const;

private:

    uint32_t* m_data;
    uint64_t m_scratch;
    int m_numBits;
    int m_numWords;
    int m_bitsWritten;
    int m_bitIndex;
    int m_wordIndex;
};
</pre>

And a bit reader that looks like this:

<pre>
class BitReader
{
public:

    BitReader( const void* data, int bytes );

    bool WouldOverflow( int bits ) const;

    uint32_t ReadBits( int bits );

    void ReadAlign();

    void ReadBytes( uint8_t* data, int bytes );

    int GetAlignBits() const;

    int GetBitsRead() const;

    int GetBytesRead() const;

    int GetBitsRemaining() const;

    int GetTotalBits() const;

    int GetTotalBytes() const;

private:

    const uint32_t* m_data;
    uint64_t m_scratch;
    int m_numBits;
    int m_numWords;
    int m_bitsRead;
    int m_bitIndex;
    int m_wordIndex;
};
</pre>

I won't go too deep into the implementation of the bitpacker above because it's fun to work out. 

You can see above from the class members the bitpacker works at the dword level (4 bytes). So it reads in and writes out dwords once filled up with bits. It uses 64bit accumulator integer and works by flushing the high 32 bits to memory once full on write. Perhaps it could be made more efficient and with less branches with a 128bit SSE integer that has the property that there is no way to overflow (and require a flush branch) if you write partial bits, then 32 bits, then another 32 bits. This could be an interesting thing to try. The cost of variable integer shift is usually pretty high so who knows.

The interesting part of a bitpacker implementation is that the write function needs a flush at the end of the write to make sure the last partial dword is written out to memory. The bit reader needs no such thing because it operates in reverse and reads in the next dword in anticipation of bits being read from it. This adds an interesting asymetry to how you read/write with the bitpacker. Also, I haven't implemented a seek function for the bitpacker above as I usually don't need it, but if you were to do so, implementing a seek would be quite challenging, requiring a flush before/after for the case of writing, and perhaps clearing of the memory to zero before you write to it or special case handling where you seek to a part of the buffer outside what has already been written to (zeros) to vs. what has already been written to (need to pull in from memory).

Regardless, it's a fairly simple thing to implement conceptually but tricky enough that you'll want to unit test it because I can tell you even after having written bitpackers from scratch at least 6 times I always find myself debugging something tricky that I get wrong.

Now when you actually get to using a bitpacker, you can replace WriteInteger/ReadInteger, WriteShort/ReadShort functions with this:

<pre>
void WriteBits( BitWriter &writer, uint32_t value, int bits );
uint32_t ReadBits( BitReader &reader, int bits );
</pre>

Of course we also want to know how many bits are required for serializing a value in some range. 

You can manually sprinkle the numbers of bits required for each value across your read/write functions like this:

<pre>
... code showing bad practice ...
</pre>

But it's easy to desync read/write bits in this way and if the value only reaches the maximum bounds rarely you can find rare asserts at runtime when a value gets large. This is really annoying.

Here is pretty common pattern in my experience:

<pre>
... Code showing typical pattern of # of bits for a value, and the max value being (1<<bits)-1 ...
</pre>

You can also use template metaprogramming to go the other way and work out the number of bits required given a maximum value:

<pre>
... Code for crazy bits required template metaprogramming ...
</pre>

At the cost of having your compiler do a bit more work. You can also calculate this at runtime if the maximum value is dynamically specified:

<pre>
... Code for runtime bits required ...
</pre>

The code above looks a bit strange but it's based on well known bit-twiddling techniques. You can read more about these techniques in "Hackers Delight" (amazon link), or on this website: *link to collection of bit twiddling techniques*. A bit esoteric but worth knowing these things are out there.

So now you can implement read/write functions per-struct like this:

<pre>
... example showing read/write per-struct ...
</pre>

This is an improvement because we're now able to serialize values up to the next bit required for the range of values, bools take one bit, a value in [0,500] takes 9 bits instead of 16 and so on.

We can still do better thought. 

Problems: First up we have to manually check each value is in range after reading it from the bitpacker so we have a bunch of manual checking to do. If we mess up this checking anywhere we leave ourselves open to a buffer overflow attack. This is bad. It would be nice if detecting out of range values was automatic rather than requiring manual code. Programmers forget.

I'll admit this is personal preference, but I really dislike having to implement separate read and write functions. It's really easy to desync read and write, especially if you add a new field to a struct, it's common to add the new field to the write function and forget to add it to the read function, leading to really hard to track down desyncs.

To solve these problems lets take a completely different approach and implement one function that performs both read and write per-struct: the serialize function.

<h2>Unified serialize function</h2>

...

==============

....

============================

Another 

It follows that for most games, there is no need 

And the flexbility of rolling your own binary format in the absence of any versioning requirement means for these sort of games there simply isn't much of a value add for these libraries in my opinion. Let me be clear though. If you do need versioning I strongly recommend you stick with one of the existing libraries. Building in versioning is a lot of work.

So in FPS, action games and so on what we typically do is embed in the game protocol a 'protocol id'. If a packet comes in with a different protocol id, it's simply ignored. There is no need to perform extensive testing of different versions of clients talking to different versions of the server (combinatorial explosion). The game protocol just ignores any packets coming in with a different protocol id and it's the responsibility of the matchmaker to match clients towards servers that have the same protocol id they do. Done.
 
This may sound a bit reckless, but most games you play work this way and have a simple technique to avoid incompatibility. On connection exchange a 'protocol id' and if the protocol id doesn't match the connection is rejected. Now there is no need to support a client and server with different protocol ids needing to be able to communicate with each other, reducing code complexity and letting you .

If you have to run multiple versions of the game because some clients have a different protocol id, usually for this transition period the matchmaker will ensure that only people with the same protocol id get to play together. (It's common during development for example to have different protocol versions in flight in the wild like different builds, local versions of a game where the protocol is slightly different to what is checked in and so on, so even before the game ships it's necessary to have solved this problem. Really it's not hard at all.)

^---------- clean up above. redundant paragraphs. rework for best flow. probably sketch out a few extra paras and merge. basic idea is correct but i'm not feeling the paragraph -> paragraph flow.

should be:

1. how do games read and write packets?
2. web background: text format, JSON etc. but it's inefficient (maybe provide an example of JSON vs. binary format)
3. cool libraries. they create the serialization for you, and add versioning
4. but we don't need versioning! => unattributed binary stream. read and write must match. there is no "overhead"
5. protocol id, never let a client and server talk to each other if they don't have the same protocol id

================

*** reading and writing struct directly ***

1. get started with reading and writing packets
2. example structs: a, b, c
3. first, attempt. lets just memcpy these structs into our packet?
4. what's wrong with this?
5. endianness. different compilers with different variable alignment settings = mismatch. can't send pointers! variable length structures, eg. c are uncoded as worst case (always sent maximum size of arrays, even if array only has a few elements)

*** read/write functions per-struct ***

1. read_integer/write_integer, read_short/write_short, read_byte/write_byte
2. pro: endian issues are solved. standardize on one network byte order and if the local machine has a different byte order, bswap before writing to the packet. do the reverse on the read, bswap after read before putting the value in the variable.
3. pro: you can now encode variable length structures. eg. encode array length, then encode each array entry only up to maximum size.
5. con: integers needing only limited number of bits need to round up to the nearest byte. eg. [0,511] only needs 9 bits, but must be sent with a full 16 bits, wasting 7 bits. a bool takes 8 bytes unless you do a lot of work to pack bools together (eg. C++ bitfields or whatever)
6. con: have to maintain separate read and write functions, if you mismatch read and write you have hard to track down desyncs :(

*** bitpacker ***

1. read_bits/write_bits, eg. write_bits( value, 9 ), read_bits( value, 9 ), write_bits( bool_value, 1 ) etc.
2. pros: you can now send a bool in just one bit. [0,511] in just one bit.
3. cons: values that aren't in full bit range, eg. [0,200] have extra values at the top of the range, and it's possible for somebody to maliciously construct a packet that gives you a value outside the range you expected, eg. you expect [0,200] for a count of entries in an array but you get 255, and you overflow your array read by 55 entries.
4. discuss bitpacker implementation, a few diagrams and so on.

*** serialize function ***

1. concept of stream. same function implements read and write.
2. serialize_int( value, min, max )
3. when a read stream is passed in, 
4. pros: much harder to desync read and write because it's the same function for read and write. you can't add a variable to the write function and forget to add it to the read function for example.
5. pros: serialize function takes min/max so if you are serializing [0,200] it'll use 8 bits, but on read you can detect if a 
value comes in outside the expected range and abort packet read.
6. pro: can use templates to generate optimized read/write functions (eg. template on stream type, ReadStream, WriteStream), this way your code is as efficient as hand written separate read/write.
7. con: use of templates in serialize functions means they need to go in a header, or be quarantined to one C++ file that does all the serialization work.
8. con: can be a bit difficult to wrap your head around writing a function that does both read and write at the same time initially.

*** arithmetic encoding / range encoding ***

1. mention for completeness.
2. most games i've worked on have only gone as far as bitpacker or serialize function. good enough.
3. you can get additional bandwidth gains (often up to 50% better) by sending fractional bits, with context.
4. for example if sending a bool true/false, but if you know that a value of 0 is 99% probability, and a value of 1 is 1% probability you can send values of 0 with less than one bit. if you are sending a value in the range [0,100] you can encode such that it effectively sends fractional bits instead of rounding up to 7 bits for a value and wasting values at the top.
5. example: link to fabien giesen's code, and the other guy.

============

Implementation details.

Drill in further on implementation of serialization function approach.

============

We're writing a binary stream. 

What I'm going to try to do here is mirror my own process developing how I read and write packets (in shipped games, and in home projects) based on what I've learned from many people, especially from Brad Pickering and Chris Fandrich on Star Wars Battlefront @ Pandemic. Also, I guess a bunch of learning from experience working with Unreal Engine @ Irrational Games and my own explorations culminating in the network protocol I developed for Journey, Playstation: All-Stars and God of War Ascension.

When you are writing a binary protocol the first place you start is usually by just writing your own C++ structures

==========

In your own custom binary protocol what you don't do is just re-implement your own half-assed version of protocol buffers. You do something different and write out an unattributed binary stream. What this mean is that the first thing you do is completely ditch versioning. 

You can do much better with your own custom binary protocol, usually encoded with a bitpacker, where the network programmer writes out an unattributed binary stream. What I mean by unattributed binary stream is that the data written out has no internal information encoded in it to describe its format. It's just pure payload. It's up to your code to make sure it reads and writes the binary data exactly the same way.

This sounds a bit daunting, but if you know a few tricks honestly it's not that hard and you 
So what I'm going to do in this article is show you exactly how I serialize packets, techiques I've build up over many shipped multiplayer games. 


What I'm going to do in this article

In this article I'll share with you how I read and write packets and how you end up here, starting at the absolute beginning and working all the way up to a unified serialize read/write function with bitpacker.

If you 

-------------

introduction. no networking in this series just reading and writing game protocol data.

some approaches: JSON, YAML, protobuffers, cap'n proto etc.

basic idea is that compatibility across different versions is required.

how we do it instead: bandwidth is the most important, we don't let different versions of the game talk to each other. protocol data is *raw*. Just the facts 'maam

first approach: reading writing structs (memcpy structs to packet)

weaknesses: not endian correct. explanation of endianness, bool takes one byte, etc. different compilers could have different packing of struct fields.

bitpacker. bool takes one bit.

separate read/write functions

weakness: you can add something to the read function and forget to update the write. easy to desync.

serialize function: read/write/measure.

strengths: difficult to desync read and write. can use templates to generate optimized read/write functions vs. runtime branches if read/write.

cons: takes a bit of time to think in multiple contexts (read and write at the same time), since using templates, lots of serialization functions must live in headers, or at minimum, one CPP file that does all the work.

examples showing various examples for reading and writing packets.

serializing integers in range [min,max]. why min/max vs. # of bits? makes signed quantities easy. easy to convert later to range encoding and to validate data coming in over the network (if outside of min/max expected range, you know the data is corrupt).

serializing tricks for read/write

serializing arrays of things

serializing floats

serializing compressed floats to a specified resolution and min/max bounds (quantize)

serializing vectors

serializing normal values

serializing quaternions

serializing magic numbers and checkpoints

bit aligning the stream

some cool tidbits about the compile time templates for determining # of bits required, link to hacker's delight bit twiddling pages. 

===================

=========================

For article in order, start with different options, eg. xml, json, key value, protobuf, capn proto, flatbuffers etc.

Discuss why game network protocols are usually not a good fit for this (version is not a problem, because different
versions of the game don't talk to each other...), bandwidth is most important, we want to only send data that is
essential, zero overhead. binary not text. => completely unattributed stream of data.

First attempt. send structs. fails because of endianness. (discussion of endianness)

next, basic read/write methods, eg. read int, write int, read byte, write byte etc. short, float etc.

separate read and write functions for packets. show what they look like.

first start writing local variables, eg. read data and process it in same function.

soon, you realize you often want to read data into a struct and separate the serialization (read/write) from the processing of the packet.

fails because often quantities are one bit only. very wasteful to spend one byte (8 bits) to send just one bit of information.

but a good start, because it is now endian correct.

bitpacker.

separate read/write functions.

easy to desync these functions, hard to track down where you went wrong.

go into details about algorithm for bitpacker (write word at a time, overflow, diagrams etc.)

solution: unify serialization function

concept of "stream". read/write mode.

avoid runtime overhead by using templates to generate optimal code for read and write.

can also have a "measure" stream for when you need to know how large something would be when encoded (all encodings are variable length, so sometimes you need to know this!)

(probably want more examples with bools in them)

need to be really safe on read. macros that return false if anything doesn't check out. DON'T USE EXCEPTIONS THEY'RE REALLY SLOW

write doesn't need to be as safe. write can assert. it's YOUR fault if you fuck up the write function and overflow bits. it shouldn't happen in production code.

redundancy. also, don't serialize # of bits for ints, instead prefer to serialize within a min/max range.

that way anything that comes in outside that range can automatically be rejected and return false (aborting the packet read)

now onto more detais about reading and writing packets

 - crc32, basic properties.
 - protocol id -- pre-header concept
 - maliciously constructed packets: need to be really safe on read (don't crash!)
 - serialize checks: end of packet. it's easy to send a truncated packet and not notice because the serialization stops (or aborts reading zeros...). adding a serialize check at the end fixes this.
 - packet journal: possible to also insert a sequence of what was written vs. what was read in another form, for validation. (blows out packet size, you'll need packet fragmentation and re-assembly to support this)

serialization examples:

...

how to go even further: range encoding. fractional bits. models. link to Fabian Giesen's example code.

next article link

=========================

For article (no particular order)

Cover checksum, possibility of corruption even with UDP checksum (16bit only)

How to write signed integers (the alternating +/-)

Floating point quantization and the +0.5 that must happen.

Other ways to write (eg. proto buffers, flatbuffers, xml, yaml etc)

Unattributed stream. We know lots of data is the same on both sides, eg. the type and bounds of a particular variable.

Matching read/write functions.

Structs. Different compilers may have different layouts/alignment. Also pointers. Can't just send those over the network.

Little and big endian.

Bitpacker working one byte at a time. Machines don't work this way.

Bitpacker working a machine word at a time (32bit), and working internally with 64bit integer. Much more modern.

The basic library (open source part) is the serializer, bitpacker, packet read/write, factory etc.

Then in later articles I can develop more example source code using this common code (the serializer) to build interesting things.

This is a good way to structure the library so that a "taste" is for free (and a very useful part...), and it is a one header library, as well as being very useful on its own, and not bloated.

Make sure that the example code does not use a bunch of STL. But don't worry too much about hardening it. eg. use "asserts" raw, use printfs, and don't use modern C++. use new/delete. If somebody wants to take this code and integrate it into their engine it should be work. This is not a middleware product.

Cover the unified serialize function.

Cover serialize read/write and template usage.

Extend tests to cover a bunch of different integer types, including bitfields.

Add examples in the article for serializing vectors, quaternions (useful).

Encoding relative integers.

Encoding quaternions with smallest three.

Encoding a value relative to another, eg. a position relative to another position.

Encoding an array of values.

Encoding a string.

Alignment of serialization.

Serialization checkpoints for safety.

Flush bits at the end of write.

Maybe extend to support seeking?

Need more unit tests for stream. They don't exercise everything.

PopCount and the code that calculates the bits required via template (compile time)

Would be nice if I could remember that trick for encoding normals from pandemic.

Common pattern of serializing a flag (bit) and if true then branching, else serialize something else.

Safety when reading and writing packets: if overflowing, don't write. If reading past end of buffer, always read zeros.

Generally, assert heavily while writing packets. While reading packets, if anything is incorrect, drop the packet.
